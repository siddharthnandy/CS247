{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS247 Advanced Data Mining - Assignment 2\n",
    "## Deadline: 11:59PM, January 31, 2023\n",
    "\n",
    "## Instructions\n",
    "Each assignment is structured as a Jupyter notebook, offering interactive tutorials that align with our lectures. You will encounter two types of problems: *write-up problems* and *coding problems*.\n",
    "\n",
    "1. **Write-up Problems:** These problems are primarily theoretical, requiring you to demonstrate your understanding of lecture concepts and to provide mathematical proofs for key theorems. Your answers should include sufficient steps for the mathematical derivations.\n",
    "2. **Coding Problems:** Here, you will be engaging with practical coding tasks. These may involve completing code segments provided in the notebooks or developing models from scratch.\n",
    "\n",
    "To ensure clarity and consistency in your submissions, please adhere to the following guidelines:\n",
    "\n",
    "* For write-up problems, use Markdown bullet points to format text answers. Also, express all mathematical equations using $\\LaTeX$ and avoid plain text such as `x0`, `x^1`, or `R x Q` for equations.\n",
    "* For coding problems, comment on your code thoroughly for readability and ensure your code is executable. Non-runnable code may lead to a loss of **all** points. Coding problems have automated grading, and altering the grading code will result in a deduction of **all** points.\n",
    "* Your submission should show the entire process of data loading, preprocessing, model implementation, training, and result analysis. This can be achieved through a mix of explanatory text cells, inline comments, intermediate result displays, and experimental visualizations.\n",
    "\n",
    "### Submission Requirements\n",
    "\n",
    "* Submit your solutions through GradeScope in BruinLearn.\n",
    "* Late submissions are allowed up to 24 hours post-deadline with a penalty factor of $\\mathbf{1}(t\\leq24)e^{-(\\ln(2)/12)t}$.\n",
    "\n",
    "### Collaboration and Integrity\n",
    "\n",
    "* Collaboration is encouraged, but all final submissions must be your own work. Please acknowledge any collaboration or external sources used, including websites, papers, and GitHub repositories.\n",
    "* Any suspicious cases of academic misconduct will be reported to The Office of the Dean of Students.\n",
    "\n",
    "## Outline\n",
    "* Part 1: Neural Networks and Deep Learning (70 points + 20 bonus points)\n",
    "* Part 2: Topic Model: Probablistic Latent Semantic Indexing (50 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Neural Networks and Deep Learning (70 points + 20 bonus points)\n",
    "\n",
    "PyTorch is a system for executing dynamic computational graphs over `Tensor` objects that behave similarly as numpy `ndarray`. It comes with a powerful automatic differentiation engine that removes the need for manual back-propagation.\n",
    "\n",
    "The objective of this exercise is to gain hands-on experience in deep learning using PyTorch, focusing on understanding and implementing different levels of abstraction and advanced training techniques in neural network development."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1.1: PyTorch Fundamentals (55 points)\n",
    "\n",
    "In the first part, we will learn to build neural networks with PyTorch. We will start with a fully-connected neural network using basic tensor operations in PyTorch and then move to a three-layer convolutional neural network using PyTorch modules. We will train our neural networks on the CIFAR-10 dataset and compare their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from torchvision import transforms as T\n",
    "from torch.utils.data import sampler, DataLoader\n",
    "\n",
    "import os\n",
    "from os import path\n",
    "\n",
    "data_path = path.join(os.getcwd(), 'data')\n",
    "\n",
    "batch_size = 64\n",
    "num_train_samples = 48000\n",
    "\n",
    "# Transformations and CIFAR-10 dataset loading\n",
    "transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(root=data_path, train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(\n",
    "    train_set, batch_size=batch_size, sampler=sampler.SubsetRandomSampler(range(num_train_samples)))\n",
    "valid_loader = DataLoader(\n",
    "    train_set, batch_size=batch_size, sampler=sampler.SubsetRandomSampler(range(num_train_samples, 50000)))\n",
    "\n",
    "test_set = torchvision.datasets.CIFAR10(root=data_path, train=False, download=True, transform=transform)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GPU Support\n",
    "\n",
    "Considering the size of the training data, it is suggested to use [Google Colab](https://colab.research.google.com/) or a GPU server for this exercise. If you are using Colab, you can manually switch to a CPU device on Colab by clicking `Runtime -> Change runtime type` and selecting `GPU` under `Hardware Accelerator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_GPU = True\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif USE_GPU and torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1: Linear Layers and ReLU Layers (12 points)\n",
    "For this exercise, we will build a two-layer fully-connected network with low-level PyTorch tensor operations.\n",
    "To be specific, we are going to implement a custom `Linear` layer and a ReLU activation layer, and understand the `forward` and `backward` passes through these layers.\n",
    "In PyTorch, `torch.autograd.Function` allows for the customization of both the forward and backward passes of an operation. For educational purposes, understanding and implementing these functions is crucial to grasp the underlying mechanics of neural networks and automatic differentiation.\n",
    "\n",
    "Caveat: The primary goal is to understand the principles rather than creating optimized code. In practical applications, one would typically use PyTorch's built-in layers and functions which are highly optimized. Thus, in typical scenarios, one only needs to define the forward pass. However, if you need a layer with a specific functionality not available in PyTorch, you will need to implement both the forward and backward passes.\n",
    "\n",
    "Firstly, let's start with (1) a custom linear layer and (2) a ReLU activation layer that uses `torch.autograd.Function` to define the `forward` and `backward` passes.\n",
    "The `forward` passes for these layers have been provided. Your task is to complete the implementation by coding the `backward` passes.\n",
    "\n",
    "**Implement the Backward Pass for the Linear Layer**: \n",
    "   - Recall that the linear layer performs a transformation $\\boldsymbol{y} = \\boldsymbol{xW}^\\top + \\boldsymbol{b}$.\n",
    "   - Your goal is to compute the gradients with respect to the input $\\boldsymbol{x}$, weights $\\boldsymbol{W}$, and bias $\\boldsymbol{b}$: $\\frac{\\partial L}{\\partial \\boldsymbol{x}}$, $\\frac{\\partial L}{\\partial \\boldsymbol{W}}$, and $\\frac{\\partial L}{\\partial \\boldsymbol{b}}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.autograd import Function\n",
    "\n",
    "# Custom Linear Layer\n",
    "class CustomLinearFunction(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input, weight, bias=None):\n",
    "        \"\"\"\n",
    "        The forward pass of the custom linear layer.\n",
    "        \n",
    "        Parameters:\n",
    "        - ctx: Context object that can be used to stash information for backward computation.\n",
    "        - input: Input tensor of shape (batch_size, input_features).\n",
    "        - weight: Weight tensor of shape (output_features, input_features).\n",
    "        - bias: Optional bias tensor of shape (output_features).\n",
    "\n",
    "        Returns:\n",
    "        - Tensor: The output of the linear transformation.\n",
    "        \"\"\"\n",
    "        ctx.save_for_backward(input, weight, bias)          # Stash input, weight, and bias for the backward pass\n",
    "        output = input.mm(weight.t())                       # Matrix multiplication\n",
    "        if bias is not None:\n",
    "            output += bias.unsqueeze(0).expand_as(output)   # Bias addition\n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        \"\"\"\n",
    "        The backward pass of the custom linear layer.\n",
    "        \n",
    "        Parameters:\n",
    "        - ctx: Context object containing saved tensors.\n",
    "        - grad_output: Gradient of the loss w.r.t. the output of this layer.\n",
    "\n",
    "        Returns:\n",
    "        - Tuple containing gradients w.r.t input, weight, and bias.\n",
    "        \"\"\"\n",
    "        input, weight, bias = ctx.saved_tensors\n",
    "        # TODO: Implement the backward pass for the linear layer\n",
    "        \n",
    "        grad_input = None\n",
    "        grad_weight = None\n",
    "        grad_bias = None\n",
    "        \n",
    "        return grad_input, grad_weight, grad_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapper class for the custom linear layer\n",
    "class CustomLinear(nn.Module):\n",
    "    def __init__(self, input_features, output_features):\n",
    "        \"\"\"\n",
    "        Custom linear layer module.\n",
    "\n",
    "        Parameters:\n",
    "        - input_features: Number of input features.\n",
    "        - output_features: Number of output features.\n",
    "        \"\"\"\n",
    "        super(CustomLinear, self).__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(output_features, input_features))\n",
    "        self.bias = nn.Parameter(torch.randn(output_features))\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        Forward pass of the custom linear module.\n",
    "\n",
    "        Parameters:\n",
    "        - input: Input tensor of shape (batch_size, input_features).\n",
    "\n",
    "        Returns:\n",
    "        - Tensor: The output of the layer.\n",
    "        \"\"\"\n",
    "        return CustomLinearFunction.apply(input, self.weight, self.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code verifies that the custom linear layer produce outputs and gradients that are close to PyTorch's own implementations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "input_features = 10\n",
    "output_features = 5\n",
    "batch_size = 3\n",
    "\n",
    "# Create a test input\n",
    "test_input_custom = torch.randn(batch_size, input_features, requires_grad=True)\n",
    "test_input_torch = test_input_custom.clone().detach().requires_grad_(True)\n",
    "\n",
    "# Custom linear layer\n",
    "custom_linear = CustomLinear(input_features, output_features)\n",
    "custom_output = custom_linear(test_input_custom)\n",
    "\n",
    "# PyTorch linear layer\n",
    "torch_linear = torch.nn.Linear(input_features, output_features)\n",
    "# Copy weights and biases from custom_linear\n",
    "torch_linear.weight.data = custom_linear.weight.data\n",
    "torch_linear.bias.data = custom_linear.bias.data\n",
    "torch_output = torch_linear(test_input_torch)\n",
    "\n",
    "# Backward pass to test gradients\n",
    "custom_output.retain_grad()\n",
    "torch_output.retain_grad()\n",
    "custom_output.sum().backward()\n",
    "torch_output.sum().backward()\n",
    "\n",
    "# Compare gradients\n",
    "assert torch.allclose(custom_linear.weight.grad, torch_linear.weight.grad, atol=1e-6)\n",
    "assert torch.allclose(custom_linear.bias.grad, torch_linear.bias.grad, atol=1e-6)\n",
    "assert torch.allclose(test_input_custom.grad, test_input_torch.grad, atol=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implement the Backward Pass for the ReLU Layer**:\n",
    "   - The ReLU function is $f(\\boldsymbol{x}) = \\max(0, \\boldsymbol{x})$.\n",
    "   - For the backward pass, calculate $\\frac{\\partial L}{\\partial \\boldsymbol{x}}$ for the ReLU layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom ReLU Activation\n",
    "class CustomReLUFunction(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        \"\"\"\n",
    "        The forward pass of the custom ReLU layer.\n",
    "\n",
    "        Parameters:\n",
    "        - ctx: Context object for backward computation.\n",
    "        - input: Input tensor.\n",
    "\n",
    "        Returns:\n",
    "        - Tensor: Output after applying ReLU.\n",
    "        \"\"\"\n",
    "        ctx.save_for_backward(input)\n",
    "        return input.clamp(min=0)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        \"\"\"\n",
    "        The backward pass of the custom ReLU layer.\n",
    "\n",
    "        Parameters:\n",
    "        - ctx: Context object containing saved tensors.\n",
    "        - grad_output: Gradient of the loss w.r.t. the output of this layer.\n",
    "\n",
    "        Returns:\n",
    "        - Tensor: Gradient w.r.t. the input.\n",
    "        \"\"\"\n",
    "        input, = ctx.saved_tensors\n",
    "\n",
    "        # TODO: Implement the backward pass for the ReLU layer\n",
    "        grad_input = None\n",
    "\n",
    "        return grad_input\n",
    "\n",
    "# Wrapper class for the custom ReLU layer\n",
    "class CustomReLU(nn.Module):\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        Forward pass of the custom ReLU module.\n",
    "\n",
    "        Parameters:\n",
    "        - input: Input tensor.\n",
    "\n",
    "        Returns:\n",
    "        - Tensor: Output after applying ReLU.\n",
    "        \"\"\"\n",
    "        return CustomReLUFunction.apply(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code checks whether the custom ReLU layer and PyTorch's built-in ReLU layer produce the same outputs and gradients for a given input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 3\n",
    "num_features = 10\n",
    "\n",
    "# Create a test input\n",
    "test_input_custom = torch.randn(batch_size, num_features, requires_grad=True)\n",
    "test_input_torch = test_input_custom.clone().detach().requires_grad_(True)\n",
    "\n",
    "# Custom ReLU layer\n",
    "custom_relu = CustomReLU()\n",
    "custom_output = custom_relu(test_input_custom)\n",
    "\n",
    "# PyTorch ReLU function\n",
    "torch_output = F.relu(test_input_torch)\n",
    "\n",
    "# Backward pass to test gradients\n",
    "custom_output.retain_grad()\n",
    "torch_output.retain_grad()\n",
    "custom_output.sum().backward()\n",
    "torch_output.sum().backward()\n",
    "\n",
    "# Compare gradients\n",
    "assert torch.allclose(test_input_custom.grad, test_input_torch.grad, atol=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2: Two-Layer Fully-Connected Networks (4 points)\n",
    "After we implemented the custom linear and ReLU layers, we can proceed to construct a two-layer fully-connected neural network.\n",
    "Implement the `TwoLayerNet` class using these custom layers. The network architecture consists of two custom linear layers separated by a custom ReLU.\n",
    "Ensure the network accepts CIFAR-10 images and outputs the correct class scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 128\n",
    "num_classes = 10\n",
    "shape = (32, 32, 3)\n",
    "\n",
    "class TwoLayerNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_dim, num_classes):\n",
    "        \"\"\"\n",
    "        Two-layer fully connected network.\n",
    "\n",
    "        Parameters:\n",
    "        - input_size: Size of each input sample.\n",
    "        - hidden_size: Size of hidden layer.\n",
    "        - num_classes: Number of output classes.\n",
    "        \"\"\"\n",
    "        super(TwoLayerNet, self).__init__()\n",
    "\n",
    "        # TODO: Define layers here\n",
    "        self.fc1 = None\n",
    "        self.fc2 = None\n",
    "        self.relu = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the network.\n",
    "\n",
    "        Parameters:\n",
    "        - x: Input tensor of shape (batch_size, input_size).\n",
    "\n",
    "        Returns:\n",
    "        - Tensor: Output of the network.\n",
    "        \"\"\"\n",
    "        # TODO: Implement the forward pass for the two-layer network\n",
    "        return x\n",
    "\n",
    "model = TwoLayerNet(input_size=np.prod(shape), hidden_dim=hidden_dim, num_classes=num_classes)\n",
    "\n",
    "# Verify that the output shape matches the expected shape\n",
    "dummy_input = torch.randn(batch_size, *shape)\n",
    "output = model(dummy_input)\n",
    "expected_output_shape = (batch_size, num_classes)\n",
    "assert output.shape == expected_output_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3: Model Evaluation (5 points)\n",
    "When training the model we will use the following function to evaluate our model on the training or validation sets.\n",
    "In our exercise, the model performance is measured in terms of classification accuracy.\n",
    "Please implement the `evaluate` function below. The function should return the classification accuracy of the model on the given dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader):\n",
    "    # TODO: Implement the evaluate function\n",
    "    model.eval()\n",
    "    accuracy = 0\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 4: Model Training (10 points)\n",
    "We can now set up a basic training loop to train our network. The training loop takes as input the neural network function, the training/validation data loader, the loss function, the optimizer, and the number of epochs to train for. The training loop should print the training loss and the accuracy of the validation set for every `print_every` epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_every = 10\n",
    "\n",
    "def train(model, train_loader, valid_loader, criterion, optimizer, epochs=20):\n",
    "    for epoch in range(epochs):\n",
    "        # TODO: Implement the training loop\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        if (epoch + 1) % print_every == 0:\n",
    "            avg_loss = running_loss / len(train_loader)\n",
    "            val_accuracy = evaluate(model, valid_loader)\n",
    "            print(f'Epoch [{epoch + 1}/{epochs}], Loss: {avg_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 5: Loss Functions and Optimizers (4 points)\n",
    "\n",
    "Composing everything together, we can now train our two-layer fully-connected network on the CIFAR-10 dataset. We will use [the cross-entropy loss](https://pytorch.org/docs/stable/nn.html#loss-functions) and the [SGD optimizer](https://pytorch.org/docs/stable/optim.html#torch.optim.SGD) with a learning rate of 1e-3 to optimize the loss function. Please refer to the PyTorch documentation for more details on the loss function and optimizer.\n",
    "Please run the training loop for 20 epochs and report the final accuracy of the model on the test set. You do not need to tune any hyperparameters at this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TwoLayerNet(input_size=np.prod(shape), hidden_dim=hidden_dim, num_classes=num_classes).to(device)\n",
    "\n",
    "# TODO: Define the loss function and the optimizer\n",
    "criterion = None\n",
    "optimizer = None\n",
    "\n",
    "# Run the training loop\n",
    "train(model, train_loader, valid_loader, criterion, optimizer, epochs=20)\n",
    "\n",
    "# TODO: Evaluate the model on the test set\n",
    "test_accuracy = None\n",
    "print(f'Test Accuracy: {test_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 6: Three-Layer Convolutional Neural Networks (6 points)\n",
    "Now let's implement a Convolutional Neural Network for CIFAR-10 classification. Your task is to build a 3-layer ConvNet followed by a two-layer fully-connected network. This network should provide a good balance between depth and complexity.\n",
    "\n",
    "Your network should consist of three convolutional layers. Each [convolutional layer](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d) is followed by a ReLU activation function and a [max-pooling layer](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html).\n",
    "- The first convolutional layer should have 32 filters.\n",
    "- The second layer should increase this to 64 filters.\n",
    "- The third layer should have 128 filters.\n",
    "- All of the convlutional layers should use a kernel size of 3x3 and a stride of 1x1.\n",
    "- Each max-pooling layer should have a kernel size of 2 and a stride of 2.\n",
    "\n",
    "After the convolutional layers, the network should have a fully connected layer leading to the final classification layer.\n",
    "The output layer should have 10 units, corresponding to the 10 classes of CIFAR-10.\n",
    "\n",
    "You should initialize the weight matrices of the convolutional layers using the [Kaiming normal initialization](https://pytorch.org/docs/stable/nn.init.html#torch.nn.init.kaiming_uniform_)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "\n",
    "        # TODO: Implement convolutional layers\n",
    "        self.conv_layers = None\n",
    "\n",
    "        # TODO: Implement the fully connected layer\n",
    "        self.fc = None\n",
    "\n",
    "        # Initialize weights using Kaiming Normal initialization\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO: Implement the forward pass\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        # TODO: Implement weight initialization using Kaiming Normal initialization\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now train the three-layer `ConvNet` defined above on CIFAR-10. This should look very similar to training the two-layer network. Again, you don't need to tune any hyperparameters, but you should achieve above 50% accuracy on the test set after training for 20 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet().to(device)\n",
    "\n",
    "# TODO: Copy the definition of the loss function and the optimizer from earlier cells\n",
    "criterion = None\n",
    "optimizer = None\n",
    "\n",
    "# Run the training loop again\n",
    "train(model, train_loader, valid_loader, criterion, optimizer, epochs=20)\n",
    "\n",
    "# TODO: Evaluate the model on the test set\n",
    "test_accuracy = None\n",
    "print(f'Test Accuracy: {test_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 7: Parameter Sizes (6 points)\n",
    "\n",
    "Consider a tensor input with shape `[1, 3, 32, 32]` (batch size = 1, channels = 3, height = 32, width = 32) and the first convolutional layer in our `ConvNet` defined as follows:\n",
    "* Kernel size = 3\n",
    "* Stride = 1\n",
    "* Padding = 1\n",
    "* Input channels = 3\n",
    "* Output channels = 32\n",
    "\n",
    "Answer the following questions:\n",
    "1. Parameter Count in Convolution Layer: Calculate the total number of parameters in this convolutional layer. Remember to consider both the filters and the biases.\n",
    "2. Total Multiplications: Estimate the total number of multiplications that occur during the forward pass through this convolutional layer. Consider the number of multiplications per element in the output feature map and the total number of elements.\n",
    "3. Fully-Connected Layer Parameters: If we replace this convolutional layer with a fully-connected layer that has the same input size and produces an output size equivalent to the convolutional layer's output shape (flattening all dimensions except for the batch into a single dimension), what would be the total number of parameters in the fully-connected layer?\n",
    "\n",
    "(Hint: You can verify your answer by implementing a convolutional layer and a fully-connected layer using PyTorch with the same input and output sizes and comparing the number of parameters: `sum(p.numel() for p in net.parameters())`.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[TODO: Write your answer here]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 8: Visualization of CNN Filters (8 points)\n",
    "\n",
    "Last, discuss how the complexity of detected features changes with each subsequent layer in the network by visualizing the output of applying the filters from the first three layers of a trained CNN to an image from the CIFAR-10 dataset.\n",
    "\n",
    "You can follow the steps below:\n",
    "1. Randomly select an image from the CIFAR-10 test set. Ensure that this image is preprocessed in the same manner as the images used during the model's training.\n",
    "2. Write a function to apply the filters of each of the first three convolutional layers to the selected image.\n",
    "For each layer, extract the output feature maps. Since layers may produce many feature maps, randomly select 10 to visualize.\n",
    "3. Using `matplotlib`, display the original image and the output feature maps for the selected filters in each layer.\n",
    "Arrange the display in a grid with the original image at the top and each subsequent row showing the feature maps for each layer.\n",
    "4. Analyze the feature maps. Describe any patterns, textures, or features that the filters appear to be detecting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[TODO: Write your answer here]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code blocks might be useful for you to visualize the output of a convolutional layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import random\n",
    "\n",
    "# Assume model is a PyTorch model and image is a single image tensor\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "num_filters = 10\n",
    "\n",
    "# Retrieve a single image from the test dataset\n",
    "images, labels = next(iter(test_loader))\n",
    "image_idx = random.randint(0, len(images) - 1)\n",
    "image = images[image_idx].to(device)\n",
    "\n",
    "# Function to plot a grid of images\n",
    "def plot_images_grid(images, title, num_rows, num_cols, axes):\n",
    "    for idx, img in enumerate(images):\n",
    "        ax_idx = idx + 1\n",
    "        ax_sub = axes[ax_idx % num_cols]\n",
    "        ax_sub.imshow(img, cmap='gray')\n",
    "        ax_sub.axis('off')\n",
    "    axes[num_cols // 2].set_title(title)\n",
    "\n",
    "# Normalize the image to display it\n",
    "norm_mean = (0.4914, 0.4822, 0.4465)\n",
    "norm_std = (0.2023, 0.1994, 0.2010)\n",
    "\n",
    "unnormalize = T.Normalize(\n",
    "    mean=[-m/s for m, s in zip(norm_mean, norm_std)],\n",
    "    std=[1/s for s in norm_std]\n",
    ")\n",
    "image_disp = unnormalize(image)\n",
    "npimg = image_disp.cpu().numpy()\n",
    "plt_image = np.transpose(npimg, (1, 2, 0))\n",
    "\n",
    "# Prepare figure\n",
    "fig, axes = plt.subplots(4, num_filters, figsize=(10, 5))\n",
    "\n",
    "# Show the raw image\n",
    "axes[0, num_filters // 2].imshow(plt_image)\n",
    "axes[0, num_filters // 2].set_title('Original Image')\n",
    "[ax.axis('off') for ax in axes[0]]\n",
    "\n",
    "# Get the outputs from the layers\n",
    "outputs = []\n",
    "layers = list(model.conv_layers.children())\n",
    "image = image.unsqueeze(0)\n",
    "for i, layer in enumerate(layers):\n",
    "    # TODO: Apply the filters of the convolutional layer to the image and store the output to the outputs list\n",
    "    pass\n",
    "\n",
    "# Visualize 10 random filters from each layer output\n",
    "for i, output in enumerate(outputs):\n",
    "    layer_filters = output[0]  # Get the filters for the first image in the batch\n",
    "    # Randomly select 10 filters\n",
    "    if layer_filters.shape[0] > num_filters:\n",
    "        selected_filters = random.sample(range(layer_filters.shape[0]), num_filters)\n",
    "    else:\n",
    "        selected_filters = range(layer_filters.shape[0])\n",
    "    filter_images = [layer_filters[idx].cpu().detach().numpy() for idx in selected_filters]\n",
    "    plot_images_grid(filter_images, f'Layer {i + 1} Filters', 1, num_filters, axes[i + 1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1.2: Hyperparameter Optimization with Ray Tune (15 points)\n",
    "Hyperparameter search is an essential part in the development of deep learning models. Ray Tune is a framework for hyperparameter optimization. It provides a simple interface for defining search spaces and supports various search algorithms such as grid search, random search, and Bayesian optimization.\n",
    "This section will explore and optimize hyperparameters for the convolutional neural network on the CIFAR-10 dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 8: Basic Setup and Grid Search (8 points)\n",
    "\n",
    "This exercise will walk through the basic setup and grid search steps for the convolutional neural network on the CIFAR-10.\n",
    "We will use Ray Tune to perform a search over the learning rate and weight decay of the network.\n",
    "\n",
    "Firstly, ensure that Ray Tune is installed in your Jupyter environment.\n",
    "If not, you can execute the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ray[tune]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define a training function `train_ray(config)` that incorporates Ray Tune.\n",
    "This function is largely similar to the `train` function in the previous section, but should (1) use `hyperparameters` from the `config` argument to initialize the optimizer and (2) report training loss using `tune.report()` at the end of each training epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray import tune\n",
    "from ray import train\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "\n",
    "# Define the training function\n",
    "def train_ray(config):\n",
    "    # Load datasets\n",
    "    train_set = torchvision.datasets.CIFAR10(root=data_path, train=True, download=True, transform=transform)\n",
    "    train_loader = DataLoader(\n",
    "        train_set, batch_size=batch_size, sampler=sampler.SubsetRandomSampler(range(num_train_samples)))\n",
    "\n",
    "    # Define the network and criterion function\n",
    "    model = ConvNet().to(device)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    # TODO: Initialize the optimizer with the hyperparameters defined in the config\n",
    "    optimizer = None \n",
    "\n",
    "    # TODO: Define the training loop. You can copy this function from the previous section\n",
    "    for _ in range(10):  # Loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "\n",
    "        # TODO: Report metrics `loss` at the end of each training epoch\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thereafter, we define an appropriate search space `config` for the two hyperparameters (learning rate and weight decay).\n",
    "You may refer to the [Tune Search Space API](https://docs.ray.io/en/latest/tune/api/search_space.html) for details.\n",
    "\n",
    "After that, use `tune.run()` to execute the search with the `ASHAScheduler` that tries to minimize the loss.\n",
    "Output and discuss the best hyperparameters found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define the hyperparameter search space\n",
    "config = {\n",
    "    'lr': None,\n",
    "    'weight_decay': None,\n",
    "}\n",
    "\n",
    "# Initialize Ray Tune\n",
    "ray.shutdown()\n",
    "ray.init()\n",
    "scheduler = ASHAScheduler(metric='loss', mode='min')\n",
    "reporter = CLIReporter(metric_columns=['loss'])\n",
    "\n",
    "# Execute the hyperparameter search\n",
    "analysis = tune.run(\n",
    "    train_ray,\n",
    "    resources_per_trial={'cpu': 1},  # If you want to use GPUs, you can set {'gpu': 1} instead\n",
    "    config=config,\n",
    "    num_samples=5,\n",
    "    scheduler=scheduler,\n",
    "    progress_reporter=reporter\n",
    ")\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_config = analysis.get_best_config(metric='loss', mode='min')\n",
    "print('Best hyperparameters found are: ', best_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 9: Hyperparameter Search with Bayesian Optimization (7 points)\n",
    "In the next exercise, we are going to implement hyperparameter optimization using an advanced search algorithm --- Bayesian Optimization and compare the results of the advanced method with the basic grid/random search from Exercise 6.\n",
    "You may refer to the [Bayesian Optimization Search](https://docs.ray.io/en/latest/tune/api/doc/ray.tune.search.bayesopt.BayesOptSearch.html#ray.tune.search.bayesopt.BayesOptSearch) for detailed understanding of the API.\n",
    "\n",
    "To implement Bayesian Optimization, we can use the same `train_ray(config)` function from previous exercises.\n",
    "However, for the search space, Bayesian Optimization works best with **continuous parameters** and a smaller search space.\n",
    "Then, we can execute the hyperparameter tuning using `BayesOptSearch` in Ray Tune."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.tune.search.bayesopt import BayesOptSearch\n",
    "\n",
    "# TODO: Initialize the BayesOptSearch object\n",
    "bayesopt = None\n",
    "\n",
    "config = {\n",
    "    'lr': None,\n",
    "    'weight_decay': None\n",
    "}\n",
    "\n",
    "analysis = tune.run(\n",
    "    train_ray,\n",
    "    resources_per_trial={'cpu': 1},  # If you want to use GPUs, you can set {'gpu': 1} instead\n",
    "    config=config,\n",
    "    num_samples=5,\n",
    "    search_alg=bayesopt,\n",
    "    scheduler=scheduler,\n",
    "    progress_reporter=reporter\n",
    ")\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_config = analysis.get_best_config(metric='loss', mode='min')\n",
    "print('Best hyperparameters found are: ', best_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ray Tune provides built-in functions that track the progress/performance of each trial, which can be retrieved from `analysis.trial_dataframes`.\n",
    "Visualize the results using `matplotlib` to show the comparison in terms of performance metrics across different hyperparameter settings.\n",
    "Last, compare the results from Exercise 6 where we implemented grid/random search with those obtained from Bayesian Optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = analysis.trial_dataframes\n",
    "\n",
    "for d in dfs.values():\n",
    "    # TODO: Plot the results\n",
    "    pass\n",
    "\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Trial Progress Over Time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1.3: CIFAR-10 Open-End Challenge (20 bonus points)\n",
    "\n",
    "The last part aims to enhance and optimize your neural network to achieve the highest possible accuracy on the CIFAR-10 dataset. This part focuses on experimenting with advanced features, layers, optimizers, and hyperparameters to improve model performance, such as:\n",
    "* [Data Augmentation](https://pytorch.org/vision/stable/transforms.html): This involves applying transformations like rotation, scaling, cropping, flipping, etc., to the training images. This can increase the diversity of the training data and help the model generalize better to new, unseen data.\n",
    "* [Batch](https://arxiv.org/abs/1502.03167)/[Layer Normalization](https://arxiv.org/abs/1607.06450): These techniques normalize the inputs to a layer within a network, helping in stabilizing and speeding up the training. Batch normalization is applied to batches of data, while layer normalization is applied across a single layer.\n",
    "* [Learning Rate Scheduling](https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate): Adjusting the learning rate during training (e.g., reducing it gradually) can help in fine-tuning the network's weights more effectively, especially as the training process progresses.\n",
    "* [Early Stopping](https://machinelearningmastery.com/early-stopping-to-avoid-overtraining-neural-network-models/): To prevent overfitting, you can monitor the validation loss and stop the training process when the loss starts to increase, indicating that the model is starting to learn noise from the training data.\n",
    "* [Residual Connections](https://arxiv.org/abs/1512.03385): Particularly useful in deep networks, residual connections help in mitigating the vanishing gradient problem by allowing an alternative shortcut path for the gradient to flow through.\n",
    "* [Regularization Techniques](https://www.deeplearningbook.org/contents/regularization.html): Techniques like L2 regularization or dropout can be used to reduce overfitting by adding a penalty to the loss function or randomly dropping out neurons during training.\n",
    "* [Adaptive Optimization Algorithms](http://pytorch.org/docs/stable/optim.html): Optimizers like [Adam](https://arxiv.org/abs/1412.6980), [RMSprop](https://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf), etc., adapt their learning rates based on the training process and can lead to faster convergence.\n",
    "\n",
    "Please briefly describe the architecture of the model and analyze the impact of different techniques on model performance.\n",
    "You need at least experiment with three advanced techniques and achieve 70% accuracy on the validation set for the **first 10 epochs**.\n",
    "\n",
    "Tips for training:\n",
    "\n",
    "* Early Indicators of Success: When tuning parameters, if they are effective, you should observe a noticeable improvement within the first few hundred iterations. This early indication is crucial for validating the direction of your hyperparameter adjustments.\n",
    "* Coarse-to-Fine Hyperparameter Tuning: Start by testing a broad range of hyperparameters over a few training iterations. This \"coarse\" search helps identify parameter sets that show any promise at all. Once you identify promising hyperparameter ranges, refine your search. This \"fine\" tuning involves more nuanced adjustments and possibly longer training epochs.\n",
    "* Validation Set for Hyperparameter Tuning: Always use the validation set for hyperparameter tuning. This set is critical for evaluating the effectiveness of your hyperparameters without tapping into the test set. Reserve the test set exclusively for the final evaluation of your model. It should only be used to assess performance after you have finalized your model's architecture and hyperparameters based on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Construct your model\n",
    "model = None\n",
    "\n",
    "# TODO: Copy the definition of the loss function and the optimizer from earlier cells\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "# TODO: Run the training loop again\n",
    "train(model, train_loader, valid_loader, criterion, optimizer, epochs=20)\n",
    "\n",
    "# TODO: Evaluate the model on the test set\n",
    "test_accuracy = evaluate(model, test_loader)\n",
    "print(f'Test Accuracy: {test_accuracy:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
